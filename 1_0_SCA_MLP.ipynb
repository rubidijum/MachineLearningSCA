{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1BUD7ZDwfBT"
   },
   "source": [
    "# SCA koriscenjem deep learninga\n",
    "\n",
    "U radu je do sada bilo prikazano nekoliko nacina izvlacenja tajni iz hardvera. State of the art pristup su template napadi koji su se pokazali kao standard u ovoj oblasti istrazivanja sigurnosti sistema. Kod template napada je potrebno ozbiljno preprocesiranje ulaznih podataka, potrebno je dosta iskustva. DPA i CPA su dovoljno jednostavni za koriscenje i implementaciju, ali je i za njih potreban relativno veliki broj trace-va i ne pokazuju se toliko dobro sa sumovitim podacima. Deep learning nastoji da eliminise neke od navedenih problema. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4GTh1TvUwNLD",
    "tags": []
   },
   "source": [
    "# Arhitekture neuronskih mreza koje ce biti koriscene\n",
    "\n",
    "U radu koji opisuje ASCAD bazu podataka date su i neke smernice oko odabira odgovarajucih modela i izbora hiperparametara. Preprocesiranje podataka i redukcija dimenzionalnosti nije potrebna, jer se ona obavi u prvim slojevima mreze.\n",
    "Architecture choice is a difficult topic..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4GTh1TvUwNLD",
    "tags": []
   },
   "source": [
    "## MLP (multi-layered perceptron)\n",
    "\n",
    "Obicna potpuno povezana neuronska mreza sa softmax aktivacijom. Broj slojeva i neurona po slojevima je tesko odrediti kao sto ce se videti u nastavku.\n",
    "\n",
    "input sloj : 80.000 tacaka traceva\n",
    "output sloj : 256 klasa za 256 mogucih vrednosti jednog bajta kljuca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avra\\Miniconda3\\envs\\ML-SCA\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "import os\n",
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from datetime import datetime\n",
    "import keras_tuner as kt\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_preparation import SCAML_Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_TYf5Vp3wM9b",
    "outputId": "dbe1a1c3-24ea-498a-8627-cd5035000d23"
   },
   "outputs": [],
   "source": [
    "EXECUTE_IN_COLAB = False\n",
    "ATTACK_ALGORITHM = 'tinyaes'\n",
    "\n",
    "if EXECUTE_IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "    \n",
    "    data_root_path = '/content/drive/MyDrive/datasets/'\n",
    "    log_root_path ='/content/drive/MyDrive/logs/'\n",
    "    \n",
    "    training_data_path = data_root_path + ATTACK_ALGORITHM + '/train'\n",
    "    testing_data_path =  data_root_path + ATTACK_ALGORITHM + '/test'\n",
    "else:    \n",
    "    data_root_path = './data/SCA_datasets/datasets/' + ATTACK_ALGORITHM\n",
    "    log_root_path = './logs/'\n",
    "    \n",
    "    training_data_path = data_root_path + '/train'\n",
    "    testing_data_path = data_root_path + '/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6c26bcbe3e42158d6d5d5261253c51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading shards:   0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3d347274764ee7872f5954c124e011",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading shards:   0%|          | 0/256 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ATTACK_POINT = 'sub_bytes_out'\n",
    "KEY_BYTE = 0\n",
    "\n",
    "# Reduce no. of trace data points\n",
    "trace_length = 10000\n",
    "\n",
    "X_train, y_train = create_data(training_data, ATTACK_POINT, KEY_BYTE, trace_length)\n",
    "X_test, y_test = create_data(testing_data, ATTACK_POINT, KEY_BYTE, trace_length)\n",
    "\n",
    "# Squeeze out the last dimension (used for CNN arch not needed for MLP arch)\n",
    "X_train = tf.squeeze(X_train)\n",
    "X_test = tf.squeeze(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape [65536 10000]\n",
      "y_train shape [65536   256]\n"
     ]
    }
   ],
   "source": [
    "print(f\"X_train shape {tf.shape(X_train)}\")\n",
    "print(f\"y_train shape {tf.shape(y_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch size: 65536\n",
      "Input shape: 10000\n"
     ]
    }
   ],
   "source": [
    "batch_size, input_vector_shape = tf.shape(X_train)[0], tf.shape(X_train)[1]\n",
    "print(f\"Training batch size: {batch_size}\\nInput shape: {input_vector_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "256it [00:00, 5224.74it/s]\n",
      "256it [00:00, 5566.63it/s]\n",
      "Loading shards:  88%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                      | 225/256 [00:40<00:05,  5.25it/s]"
     ]
    }
   ],
   "source": [
    "dataset = SCAML_Dataset()\n",
    "\n",
    "training_array = dataset.load_shards(training_data_path)\n",
    "testing_array = dataset.load_shards(testing_data_path)\n",
    "\n",
    "ATTACK_POINT = 'sub_bytes_out'\n",
    "ATTACK_BYTE = 0\n",
    "\n",
    "(X_train, y_train) = dataset.create_data(training_array, ATTACK_POINT, ATTACK_BYTE, 10000)\n",
    "(X_test, y_test, keys, plaintexts) = dataset.create_data(testing_array, ATTACK_POINT, ATTACK_BYTE, 10000, attack = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_vector_shape = X_train_scaaml.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Keras API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (Dense)         (None, 10000)             100010000 \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 10000)             0         \n",
      "                                                                 \n",
      " layer_1 (Dense)             (None, 5000)              50005000  \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 5000)              0         \n",
      "                                                                 \n",
      " layer_2 (Dense)             (None, 2500)              12502500  \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 2500)              0         \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 256)               640256    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 163,157,756\n",
      "Trainable params: 163,157,756\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "leaky_relu_alpha = 0.2\n",
    "\n",
    "MLP_sequential_base = keras.models.Sequential()\n",
    "\n",
    "# Input layer\n",
    "MLP_sequential_base.add(\n",
    "    keras.layers.Dense(\n",
    "        name='input_layer',\n",
    "        units=10000,\n",
    "        input_dim=input_vector_shape\n",
    "    )\n",
    ")\n",
    "\n",
    "MLP_sequential_base.add(keras.layers.LeakyReLU(alpha=leaky_relu_alpha))\n",
    "\n",
    "# Hidden layer 1\n",
    "MLP_sequential_base.add(\n",
    "    keras.layers.Dense(\n",
    "        name='layer_1',\n",
    "        units=5000\n",
    "    )\n",
    ")\n",
    "\n",
    "MLP_sequential_base.add(keras.layers.LeakyReLU(alpha=leaky_relu_alpha))\n",
    "\n",
    "# Hidden layer 2\n",
    "MLP_sequential_base.add(\n",
    "    keras.layers.Dense(\n",
    "        name='layer_2',\n",
    "        units=2500,\n",
    "        activation='relu'\n",
    "    )\n",
    ")\n",
    "\n",
    "MLP_sequential_base.add(keras.layers.LeakyReLU(alpha=leaky_relu_alpha))\n",
    "\n",
    "# # Hidden layer 3\n",
    "# MLP_sequential_base.add(\n",
    "#     keras.layers.Dense(\n",
    "#         name='layer_3',\n",
    "#         units=2500,\n",
    "#         activation='relu'\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# # Hidden layer 4\n",
    "# MLP_sequential_base.add(\n",
    "#     keras.layers.Dense(\n",
    "#         name='layer_4',\n",
    "#         units=2500,\n",
    "#         activation='relu'\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# Output layer\n",
    "MLP_sequential_base.add(\n",
    "    keras.layers.Dense(\n",
    "        name='output_layer',\n",
    "        units=256,\n",
    "        activation='softmax'\n",
    "    )\n",
    ")\n",
    "\n",
    "MLP_base_optimizer = tf.keras.optimizers.Adam(learning_rate=0.003)\n",
    "\n",
    "MLP_sequential_base.compile(loss='categorical_crossentropy', \n",
    "                 optimizer=MLP_base_optimizer, \n",
    "                 metrics=['accuracy',\n",
    "                         'Recall'])\n",
    "\n",
    "MLP_sequential_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './images/sequential'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m model_img_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./images/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m MLP_sequential_base\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMLP_sequential_base\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_img_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\ML-SCA\\lib\\site-packages\\keras\\utils\\vis_utils.py:434\u001b[0m, in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, layer_range, show_layer_activations)\u001b[0m\n\u001b[0;32m    432\u001b[0m   extension \u001b[38;5;241m=\u001b[39m extension[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# Save image to disk.\u001b[39;00m\n\u001b[1;32m--> 434\u001b[0m \u001b[43mdot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextension\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    435\u001b[0m \u001b[38;5;66;03m# Return the image as a Jupyter Image object, to be displayed in-line.\u001b[39;00m\n\u001b[0;32m    436\u001b[0m \u001b[38;5;66;03m# Note that we cannot easily detect whether the code is running in a\u001b[39;00m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;66;03m# notebook, and thus we always return the Image if Jupyter is available.\u001b[39;00m\n\u001b[0;32m    438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m extension \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpdf\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\ML-SCA\\lib\\site-packages\\pydot.py:1818\u001b[0m, in \u001b[0;36mDot.write\u001b[1;34m(self, path, prog, format, encoding)\u001b[0m\n\u001b[0;32m   1816\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1817\u001b[0m     s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcreate(prog, \u001b[38;5;28mformat\u001b[39m, encoding\u001b[38;5;241m=\u001b[39mencoding)\n\u001b[1;32m-> 1818\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mwb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m   1819\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(s)\n\u001b[0;32m   1820\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './images/sequential'"
     ]
    }
   ],
   "source": [
    "#TODO: create before writing\n",
    "model_img_path = './images/' + MLP_sequential_base.name\n",
    "tf.keras.utils.plot_model(MLP_sequential_base, show_shapes=True, to_file=model_img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, X_train, y_train, batch_size, epochs, validation_data, plot_metrics=True):\n",
    "    \"\"\"! Train model and log training process to tensorboard\n",
    "    \n",
    "    @param model Model to train\n",
    "    @param X_train Model inputs\n",
    "    @param y_train Correct labels\n",
    "    @param batch_size Size of the input batch\n",
    "    @param epochs Number of epochs to train\n",
    "    @param validation_data Validation data tuple in the format (X_val, y_val)\n",
    "    \"\"\"\n",
    "        \n",
    "    _log_dir = './logs/' + 'MLP_' + datetime.now().strftime(\"%Y-%d-%m_%H-%M\")\n",
    "\n",
    "    callbacks_list = [\n",
    "        tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3),\n",
    "        tf.keras.callbacks.TensorBoard(log_dir=_log_dir, histogram_freq=1)\n",
    "    ]\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        verbose=1,\n",
    "        validation_data = validation_data,\n",
    "        callbacks=callbacks_list\n",
    "    )\n",
    "    \n",
    "#     if plot_metrics:\n",
    "#         model.metrics\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Unable to serialize 10000 to JSON. Unrecognized type <class 'tensorflow.python.framework.ops.EagerTensor'>.\n",
      "Epoch 1/10\n",
      "656/656 [==============================] - 460s 701ms/step - loss: 91.8618 - accuracy: 0.0031 - recall: 3.5095e-04 - val_loss: 5.5455 - val_accuracy: 0.0039 - val_recall: 0.0000e+00\n",
      "Epoch 2/10\n",
      "656/656 [==============================] - 484s 730ms/step - loss: 5.5470 - accuracy: 0.0037 - recall: 0.0000e+00 - val_loss: 5.5453 - val_accuracy: 0.0039 - val_recall: 0.0000e+00\n",
      "Epoch 3/10\n",
      "656/656 [==============================] - 474s 719ms/step - loss: 5.5470 - accuracy: 0.0034 - recall: 0.0000e+00 - val_loss: 5.5453 - val_accuracy: 0.0039 - val_recall: 0.0000e+00\n",
      "Epoch 4/10\n",
      "656/656 [==============================] - 500s 728ms/step - loss: 5.5470 - accuracy: 0.0036 - recall: 0.0000e+00 - val_loss: 5.5453 - val_accuracy: 0.0039 - val_recall: 0.0000e+00\n",
      "Epoch 5/10\n",
      "656/656 [==============================] - 556s 829ms/step - loss: 5.5470 - accuracy: 0.0034 - recall: 0.0000e+00 - val_loss: 5.5453 - val_accuracy: 0.0039 - val_recall: 0.0000e+00\n",
      "Epoch 6/10\n",
      "656/656 [==============================] - 475s 715ms/step - loss: 5.5471 - accuracy: 0.0031 - recall: 0.0000e+00 - val_loss: 5.5453 - val_accuracy: 0.0039 - val_recall: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# Train base MLP\n",
    "history = train_model(MLP_sequential_base, X_train, y_train, 100, 10, (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_accuracy = [1/256] * len(history.history['val_accuracy'])\n",
    "\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(random_accuracy)\n",
    "plt.legend(['val_acc', 'acc', 'random'],loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model gotovo nista nije naucio i preciznost je cak i gora od nasumicnog pogadjanja (1/256 ~ 0.0039)\n",
    "Stoga nema puno smisla evaluirati model i vrsiti kriptografske transformacije kako bi se otkrio kljuc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypertuning\n",
    "\n",
    "Posto su rezultati treninga \"na slepo\" nezavidni, bice koriscen tuner hiperparametara keras ekosistema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential model builder\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten())\n",
    "    \n",
    "    no_layers = hp.Int('num_layers', min_value=2, max_value=10)\n",
    "    for layer in range(no_layers):\n",
    "        model.add(\n",
    "            keras.layers.Dense(\n",
    "                units = hp.Int('units', min_value=500, max_value=5000, step=1000),\n",
    "                activation = 'relu'\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # Optimize for batch normalization\n",
    "        if layer == int(no_layers/2) and hp.Boolean('BatchNormalize'):\n",
    "            model.add(keras.layers.BatchNormalization())\n",
    "            \n",
    "        model.add(keras.layers.LeakyReLU())\n",
    "\n",
    "    model.add(keras.layers.Dense(units=256, activation='softmax'))\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4, 1e-5])\n",
    "    \n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                    loss=\"categorical_crossentropy\",\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project ./logs/hyperparam_tuning\\MLP_SCA_1.0\\oracle.json\n",
      "Search space summary\n",
      "Default search space size: 4\n",
      "num_layers (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 10, 'step': 1, 'sampling': None}\n",
      "units (Int)\n",
      "{'default': None, 'conditions': [], 'min_value': 500, 'max_value': 5000, 'step': 1000, 'sampling': None}\n",
      "BatchNormalize (Boolean)\n",
      "{'default': False, 'conditions': []}\n",
      "learning_rate (Choice)\n",
      "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001, 1e-05], 'ordered': True}\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.RandomSearch(hypermodel=build_model,\n",
    "                    objective='val_accuracy',\n",
    "                    max_trials=15,\n",
    "                    executions_per_trial=2,\n",
    "                    directory='./logs/hyperparam_tuning',\n",
    "                    project_name='MLP_SCA_1.0')\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #2\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "num_layers        |10                |?                 \n",
      "units             |4500              |?                 \n",
      "BatchNormalize    |True              |?                 \n",
      "learning_rate     |0.001             |?                 \n",
      "\n",
      "Epoch 1/10\n",
      "2048/2048 [==============================] - 1501s 732ms/step - loss: 5.5615 - accuracy: 0.0032 - val_loss: 5.5453 - val_accuracy: 0.0039\n",
      "Epoch 2/10\n",
      "2048/2048 [==============================] - 1559s 761ms/step - loss: 5.5473 - accuracy: 0.0027 - val_loss: 5.5452 - val_accuracy: 0.0039\n",
      "Epoch 3/10\n",
      "2048/2048 [==============================] - 1543s 754ms/step - loss: 5.5464 - accuracy: 0.0034 - val_loss: 5.5452 - val_accuracy: 0.0039\n",
      "Epoch 4/10\n",
      "2048/2048 [==============================] - 1544s 754ms/step - loss: 5.5464 - accuracy: 0.0028 - val_loss: 5.5452 - val_accuracy: 0.0039\n",
      "Epoch 5/10\n",
      "1084/2048 [==============>...............] - ETA: 10:58 - loss: 5.5460 - accuracy: 0.0032"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 7>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m early_stop_callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      5\u001b[0m tensorboard_callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mTensorBoard(tensorboard_path)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m             \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m             \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m             \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m             \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stop_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m                       \u001b[49m\u001b[43mtensorboard_callback\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\ML-SCA\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py:179\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[1;32m--> 179\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrun_trial(trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs)\n\u001b[0;32m    180\u001b[0m \u001b[38;5;66;03m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[39;00m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m results \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\ML-SCA\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:304\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    302\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[0;32m    303\u001b[0m copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[1;32m--> 304\u001b[0m obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_and_fit_model(trial, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;66;03m# objective left unspecified,\u001b[39;00m\n\u001b[0;32m    307\u001b[0m \u001b[38;5;66;03m# and objective value is not a single float.\u001b[39;00m\n\u001b[0;32m    308\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    309\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj_value, (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m))\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault_objective\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    311\u001b[0m ):\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\ML-SCA\\lib\\site-packages\\keras_tuner\\engine\\tuner.py:234\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[0;32m    233\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[1;32m--> 234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhypermodel\u001b[38;5;241m.\u001b[39mfit(hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\ML-SCA\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py:137\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[0;32m    115\u001b[0m \n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\ML-SCA\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\ML-SCA\\lib\\site-packages\\keras\\engine\\training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1377\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1378\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1379\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1380\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1381\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[0;32m   1382\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1383\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1384\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1385\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1386\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\ML-SCA\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\ML-SCA\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\ML-SCA\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateless_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\ML-SCA\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2953\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2954\u001b[0m   (graph_function,\n\u001b[0;32m   2955\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2957\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\ML-SCA\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1849\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1851\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1852\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1853\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1854\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1855\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1856\u001b[0m     args,\n\u001b[0;32m   1857\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1858\u001b[0m     executing_eagerly)\n\u001b[0;32m   1859\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\ML-SCA\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    498\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 499\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    505\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    506\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    507\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    508\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    511\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    512\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\Miniconda3\\envs\\ML-SCA\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tensorboard_path  = \"./logs/hyperparam_tuning/MLP_RandomSearch\"\n",
    "intermediate_path = \"./logs/hyperparam_tuning/MLP_RandomSearch/tmp\"\n",
    "\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(tensorboard_path)\n",
    "\n",
    "tuner.search(X_train, \n",
    "             y_train, \n",
    "             epochs=10, \n",
    "             validation_data=(X_test, y_test), \n",
    "             callbacks=[early_stop_callback,\n",
    "                       tensorboard_callback]\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(65536, 256), dtype=uint8, numpy=\n",
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functional Keras API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "inputs = keras.Input(shape = (input_vector_shape,))\n",
    "\n",
    "# Hidden layer 1\n",
    "x = keras.layers.Dense(name='hidden_layer_1', units=10000, activation='relu')(inputs)\n",
    "\n",
    "# Hidden layer 2\n",
    "x = keras.layers.Dense(name='hidden_layer_2', units=5000, activation='relu')(x)\n",
    "\n",
    "# Batch normalization layer\n",
    "x = keras.layers.BatchNormalization(name='batch_norm_1')(x)\n",
    "\n",
    "# Hidden layer 3\n",
    "x = keras.layers.Dense(name='hidden_layer_3', units=2500, activation='relu')(x)\n",
    "\n",
    "# Hidden layer 4\n",
    "x = keras.layers.Dense(name='hidden_layer_4', units=1000, activation='relu')(x)\n",
    "\n",
    "# Batch normalization layer\n",
    "x = keras.layers.BatchNormalization(name='batch_norm_2')(x)\n",
    "\n",
    "# Hidden layer 5\n",
    "x = keras.layers.Dense(name='hidden_layer_5', units=500, activation='relu')(x)\n",
    "\n",
    "# Output layer\n",
    "outputs = keras.layers.Dense(name='output_layer', units=256, activation='softmax')(x)\n",
    "\n",
    "MLP_functional = keras.Model(inputs=inputs, outputs=outputs, name='functional_MLP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_functional.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(MLP_functional, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLP_test_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "MLP_functional.compile(loss='categorical_crossentropy', \n",
    "                 optimizer=MLP_test_optimizer, \n",
    "                 metrics=['accuracy', 'Recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v-JTyUqbz-zJ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "log_dir = './logs/' + 'MLP_' + datetime.now().strftime(\"%Y-%d-%m_%H-%M\")\n",
    "\n",
    "callbacks_list = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "]\n",
    "\n",
    "history = MLP_test.fit(\n",
    "    X_train_reduced,\n",
    "    y_train,\n",
    "    batch_size=32,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    validation_data = (X_test_reduced, y_test),\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hypertuning functional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt\n",
    "\n",
    "min_layers = 4\n",
    "max_layers = 15\n",
    "\n",
    "def build_model(hp):\n",
    "    \n",
    "    inputs = keras.Input(shape = (input_vector_shape,))\n",
    "    \n",
    "    x = inputs\n",
    "    \n",
    "    no_layers = hp.Int('num_layers', min_value=min_layers, max_value=max_layers)\n",
    "    for layer in range(no_layers):\n",
    "        \n",
    "        x = keras.layers.Dense(units = hp.Int('units', min_value=500, max_value=10000, step=1000),\n",
    "                               activation = 'relu')(x)\n",
    "        \n",
    "        # Optimize for batch normalization\n",
    "        if layer == int(no_layers/2) and hp.Boolean('BatchNormalize'):\n",
    "            x = keras.layers.BatchNormalization()(x)\n",
    "        \n",
    "\n",
    "    outputs = keras.layers.Dense(units=256, activation='softmax')(x)\n",
    "    # Tune the learning rate for the optimizer\n",
    "    # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4, 1e-5, 3e-2, 3e-3, 3e-4, 3e-5, 5e-2, 5e-3, 5e-4, 5e-5])\n",
    "#     hp_learning_rate = hp.Float(\"lr\", min_value=1e-5, max_value=1e-2, sampling=\"log\")\n",
    "\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                    loss=\"categorical_crossentropy\",\n",
    "                    metrics=['accuracy',\n",
    "                             'Recall'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(hypermodel=build_model,\n",
    "                        objective='val_accuracy',\n",
    "                        max_epochs=5,\n",
    "                        hyperband_iterations=10,\n",
    "                        overwrite=True,\n",
    "                        directory='./logs/hyperparam_tuning',\n",
    "                        project_name='MLP_SCA')\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_path = \"./logs/hyperparam_tuning/tensorboard\"\n",
    "intermediate_path = \"./logs/tmp_func\"\n",
    "\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(tensorboard_path)\n",
    "\n",
    "tuner.search(X_train_squeezed[:,:20000], \n",
    "             y_train, \n",
    "             epochs=10, \n",
    "             validation_data=(X_test_squeezed[:,:20000], y_test), \n",
    "             callbacks=[early_stop_callback,\n",
    "                       tensorboard_callback]\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./logs/MLP_2022-19-08_12-58"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "U relativno malom broju epoha je funkcija gubitka prestala da se smanjuje. Moze se uvesti uslov ranijeg zaustavljanja ka callback u keras API-ju"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = './models'\n",
    "model_name = '/MLP_base_0.3'\n",
    "\n",
    "MLP_test.save(models_path + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot()\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot()\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = './models'\n",
    "model_name = '/MLP_base'\n",
    "\n",
    "MLP_test.save(models_path + model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "predictions = MLP_test.predict(X_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.utils.np_utils.to_categorical(predictions[0].max(), 256)\n",
    "key_guess = np.argmax(predictions[0])\n",
    "print(key_guess)\n",
    "print(predictions[0][key_guess])\n",
    "print(np.max(predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_classes = keras.utils.np_utils.to_categorical(np.argmax(predictions, axis=1), 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(prediction_classes, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_success = np.sum(np.all(prediction_classes == labels, axis=1))\n",
    "print(f\"Model accuracy: {(prediction_success/X_train_.shape[0]) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypertuning\n",
    "\n",
    "Posto je ocigledno da se manualno napravljene mreze ponasaju veoma lose, odnosno nemaju nikakav ucinak na validacionom skupu podataka, potrebno je izmeniti parametre modela. Za ovo ce biti koriscen alat keras tuner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequential model builder\n",
    "\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "    model.add(keras.layers.Flatten())\n",
    "    \n",
    "    for no_layers in range(hp.Int('num_layers', min_value=4, max_value=10)):\n",
    "        model.add(\n",
    "            keras.layers.Dense(\n",
    "                units = hp.Int('units', min_value=500, max_value=5000, step=1000),\n",
    "                activation = 'relu'\n",
    "            )\n",
    "        )\n",
    "\n",
    "    model.add(keras.layers.Dense(units=256, activation='softmax'))\n",
    "    hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4, 1e-5])\n",
    "#     hp_learning_rate = hp.Float(\"lr\", min_value=1e-5, max_value=1e-2, sampling=\"log\")\n",
    "\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                    loss=\"categorical_crossentropy\",\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = kt.Hyperband(hypermodel=build_model,\n",
    "                    objective='val_accuracy',\n",
    "                    max_epochs=5,\n",
    "                    hyperband_iterations=10)\n",
    "\n",
    "tuner.search_space_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_path = \"/logs\"\n",
    "intermediate_path = \"/logs/tmp\"\n",
    "\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2)\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(tensorboard_path)\n",
    "\n",
    "tuner.search(X_train[:,:20000,:], \n",
    "             y_train, \n",
    "             epochs=10, \n",
    "             validation_data=(X_test[:,:20000,:], y_test), \n",
    "             callbacks=[early_stop_callback,\n",
    "                       tensorboard_callback]\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters = tuner.get_best_hyperparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyperparameters[0].get('layers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4GTh1TvUwNLD",
    "tags": []
   },
   "source": [
    "### ResNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4GTh1TvUwNLD",
    "tags": []
   },
   "source": [
    "### CNN (Convolutional Neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_config(config_name, config):\n",
    "    \"\"\"Pretty print a config object in terminal.\n",
    "    Args:\n",
    "        config_name (str): name of the config\n",
    "        config (dict): config to display\n",
    "    \"\"\"\n",
    "    cprint(f\"[{config_name}]\", \"magenta\")\n",
    "    cnt = 1\n",
    "    for k, v in config.items():\n",
    "        if cnt % 2:\n",
    "            color = \"cyan\"\n",
    "        else:\n",
    "            color = \"yellow\"\n",
    "        cprint(f\"{k}:{v}\", color)\n",
    "        cnt += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2020 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\"\"\"Intro model.\"\"\"\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def block(x,\n",
    "          filters,\n",
    "          kernel_size=3,\n",
    "          strides=1,\n",
    "          conv_shortcut=False,\n",
    "          activation=\"relu\"):\n",
    "    \"\"\"Residual block with pre-activation\n",
    "    From: https://arxiv.org/pdf/1603.05027.pdf\n",
    "\n",
    "    Args:\n",
    "        x: input tensor.\n",
    "        filters (int): filters of the bottleneck layer.\n",
    "\n",
    "        kernel_size(int, optional): kernel size of the bottleneck layer.\n",
    "        defaults to 3.\n",
    "\n",
    "        strides (int, optional): stride of the first layer.\n",
    "        defaults to 1.\n",
    "\n",
    "        conv_shortcut (bool, optional): Use convolution shortcut if True,\n",
    "        otherwise identity shortcut. Defaults to False.\n",
    "\n",
    "        use_batchnorm (bool, optional): Use batchnormalization if True.\n",
    "        Defaults to True.\n",
    "\n",
    "        activation (str, optional): activation function. Defaults to \"relu\".\n",
    "\n",
    "    Returns:\n",
    "        Output tensor for the residual block.\n",
    "    \"\"\"\n",
    "\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activation)(x)\n",
    "\n",
    "    if conv_shortcut:\n",
    "        shortcut = layers.Conv1D(4 * filters, 1, strides=strides)(x)\n",
    "    else:\n",
    "        if strides > 1:\n",
    "            shortcut = layers.MaxPooling1D(1, strides=strides)(x)\n",
    "        else:\n",
    "            shortcut = x\n",
    "\n",
    "    x = layers.Conv1D(filters, 1, use_bias=False, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activation)(x)\n",
    "\n",
    "    x = layers.Conv1D(filters,\n",
    "                      kernel_size,\n",
    "                      strides=strides,\n",
    "                      use_bias=False,\n",
    "                      padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(activation)(x)\n",
    "\n",
    "    x = layers.Conv1D(4 * filters, 1)(x)\n",
    "    x = layers.Add()([shortcut, x])\n",
    "    return x\n",
    "\n",
    "\n",
    "def stack(x, filters, blocks, kernel_size=3, strides=2, activation=\"relu\"):\n",
    "    \"\"\"A set of stacked residual blocks.\n",
    "    Args:\n",
    "        filters (int): filters of the bottleneck layer.\n",
    "\n",
    "        blocks (int): number of conv blocks to stack.\n",
    "\n",
    "        kernel_size(int, optional): kernel size of the bottleneck layer.\n",
    "        defaults to 3.\n",
    "\n",
    "        strides (int, optional): stride used in the last block.\n",
    "        defaults to 2.\n",
    "\n",
    "        conv_shortcut (bool, optional): Use convolution shortcut if True,\n",
    "        otherwise identity shortcut. Defaults to False.\n",
    "\n",
    "        activation (str, optional): activation function. Defaults to \"relu\".\n",
    "\n",
    "    Returns:\n",
    "        tensor:Output tensor for the stacked blocks.\n",
    "  \"\"\"\n",
    "    x = block(x,\n",
    "              filters,\n",
    "              kernel_size=kernel_size,\n",
    "              activation=activation,\n",
    "              conv_shortcut=True)\n",
    "    for _ in range(2, blocks):\n",
    "        x = block(x, filters, kernel_size=kernel_size, activation=activation)\n",
    "    x = block(x, filters, strides=strides, activation=activation)\n",
    "    return x\n",
    "\n",
    "\n",
    "def Resnet1D(input_shape, attack_point, mdl_cfg, optim_cfg):  # pylint: disable=C0103\n",
    "    del attack_point  # unused\n",
    "\n",
    "    pool_size = mdl_cfg[\"initial_pool_size\"]\n",
    "    filters = mdl_cfg[\"initial_filters\"]\n",
    "    block_kernel_size = mdl_cfg[\"block_kernel_size\"]\n",
    "    activation = mdl_cfg[\"activation\"]\n",
    "    dense_dropout = mdl_cfg[\"dense_dropout\"]\n",
    "    num_blocks = [\n",
    "        mdl_cfg[\"blocks_stack1\"], mdl_cfg[\"blocks_stack2\"],\n",
    "        mdl_cfg[\"blocks_stack3\"], mdl_cfg[\"blocks_stack4\"]\n",
    "    ]\n",
    "\n",
    "    inputs = layers.Input(shape=(input_shape))\n",
    "    x = inputs\n",
    "\n",
    "    # stem\n",
    "    x = layers.MaxPool1D(pool_size=pool_size)(x)\n",
    "\n",
    "    # trunk: stack of residual block\n",
    "    for block_idx in range(4):\n",
    "        filters *= 2\n",
    "        x = stack(x,\n",
    "                  filters,\n",
    "                  num_blocks[block_idx],\n",
    "                  kernel_size=block_kernel_size,\n",
    "                  activation=activation)\n",
    "\n",
    "    # head model: dense\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    for _ in range(1):\n",
    "        x = layers.Dropout(dense_dropout)(x)\n",
    "        x = layers.Dense(256)(x)\n",
    "        x = layers.BatchNormalization()(x)\n",
    "        x = layers.Activation(activation)(x)\n",
    "\n",
    "    outputs = layers.Dense(256, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    model.summary()\n",
    "\n",
    "    lr = optim_cfg[\"lr\"]\n",
    "\n",
    "    model.compile(loss=[\"categorical_crossentropy\"],\n",
    "                  metrics=[\"acc\"],\n",
    "                  optimizer=Adam(lr))\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_model(input_shape, attack_point, config):\n",
    "    \"\"\"Return an instantiated model based of the config provided.\n",
    "\n",
    "    Args:\n",
    "        config (dict): scald config.\n",
    "    \"\"\"\n",
    "\n",
    "    mdl_cfg = config[\"model_parameters\"]\n",
    "    optim_cfg = config[\"optimizer_parameters\"]\n",
    "\n",
    "    display_config(\"model\", mdl_cfg)\n",
    "    display_config(\"optimizer\", optim_cfg)\n",
    "    return Resnet1D(input_shape, attack_point, mdl_cfg, optim_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cprint import cprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"model\": \"cnn\",\n",
    "    \"device\": \"stm32f415\",\n",
    "    \"algorithm\": \"tinyaes\",\n",
    "    \"version\": \"10\",\n",
    "    \"attack_points\": [\n",
    "        \"sub_bytes_out\"\n",
    "    ],\n",
    "    \"attack_bytes\": [\n",
    "        \"0\"\n",
    "    ],\n",
    "    \"max_trace_len\": 10000,\n",
    "    \"num_shards\": 256,\n",
    "    \"num_traces_per_shard\": 256,\n",
    "    \"batch_size\": 32,\n",
    "    \"epochs\": 10,\n",
    "    \"optimizer_parameters\": {\n",
    "        \"lr\": 0.001,\n",
    "        \"multi_gpu_lr\": 0.001\n",
    "    },\n",
    "    \"model_parameters\": {\n",
    "        \"activation\": \"relu\",\n",
    "        \"initial_filters\": 8,\n",
    "        \"initial_pool_size\": 4,\n",
    "        \"block_kernel_size\": 3,\n",
    "        \"blocks_stack1\": 3,\n",
    "        \"blocks_stack2\": 4,\n",
    "        \"blocks_stack3\": 4,\n",
    "        \"blocks_stack4\": 3,\n",
    "        \"dense_dropout\": 0.1\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from termcolor import cprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scaml = get_model(X_train[:,:20000,:].shape[1:], 'sub_bytes_out', cfg )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scaml.fit(X_train[:,:20000,:],\n",
    "          y_train,\n",
    "          validation_data=(X_test[:,:20000,:], y_test),\n",
    "          verbose=1,\n",
    "          epochs=cfg[\"epochs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaml_predictions = model_scaml.predict(X_test[:,:20000,:], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaml_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.argmax(scaml_predictions, axis=1).shape)\n",
    "print(np.argmax(scaml_predictions, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(training_data[0]['sub_bytes_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scaml.save(models_path + '/scaml_model_trained')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tips:\n",
    "\n",
    "## start simple (underfit) or start complex (overfit)\n",
    "\n",
    "## Don't need great accuracy => slightly above random could work with enough traces"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "authorship_tag": "ABX9TyNPPufLW+alIzuPVjTMR02P",
   "collapsed_sections": [],
   "name": "1.0 SCA MLP.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0eb94c0b4e224171b294f5101577b056": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "130e6f00dd5b41fc934aa3b1884492f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_50dc2fa20d8d4f139aa4511039d9048e",
       "IPY_MODEL_ee5770baf6ec4623b0e9e89d154d3da8",
       "IPY_MODEL_780939f5f5334091b454048ddaf4a3f3"
      ],
      "layout": "IPY_MODEL_0eb94c0b4e224171b294f5101577b056"
     }
    },
    "34367596798d4c08a60b676ddf12c233": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50dc2fa20d8d4f139aa4511039d9048e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_34367596798d4c08a60b676ddf12c233",
      "placeholder": "​",
      "style": "IPY_MODEL_fd1be6e3e2c14557b37839c66a3a6c56",
      "value": "Loading training shards: 100%"
     }
    },
    "67b405019570413aa06f6f6a353e7a05": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6836140afee84cc1abc2ad0bfb0b20aa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "780939f5f5334091b454048ddaf4a3f3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_67b405019570413aa06f6f6a353e7a05",
      "placeholder": "​",
      "style": "IPY_MODEL_a36533231f2f492ea8b8623852596b32",
      "value": " 50/50 [00:19&lt;00:00,  2.52it/s]"
     }
    },
    "a36533231f2f492ea8b8623852596b32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "db14652317ac4982a8d0b70ab782eab7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee5770baf6ec4623b0e9e89d154d3da8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_db14652317ac4982a8d0b70ab782eab7",
      "max": 50,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_6836140afee84cc1abc2ad0bfb0b20aa",
      "value": 50
     }
    },
    "fd1be6e3e2c14557b37839c66a3a6c56": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
